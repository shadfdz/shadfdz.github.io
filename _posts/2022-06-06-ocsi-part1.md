---
layout: post
title: "Analyizing Online Shopper Intention - Part 1"
subtitle: "CRISP-DM, Understanding the Data, Exploratory Data Analysis"
date: 2022-06-06 08:06:13 -0400
background: '/img/posts/ocsi_part1/4th.jpeg'
---

## Starting a Data Science Project

Let's start a data science project from scratch. In this series, we will analyze online customer intention ([source](https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset)) by following the [CRISP-DM](https://www.ibm.com/docs/en/spss-modeler/SaaS?topic=dm-crisp-help-overview) data science lifecycle process. For part 1, we're going to setup our project, understand our data, and perform exploratory data analysis. For part 2, we're going to focus on data cleansing and feature engineering methods. Part 3 will involve modeling our data and Part 4 will be deployment of our model using Flask and Docker. Whew.


## Setting Up the Workspace 
For the project structure, requirements, and setup, please checkout the project's github [repo](https://github.com/shadfdz/crispy-octo-spoon). Go ahead checkout the readme for instructions on how to setup your virtual environment if you want to do so. We will also be using pre-commit hooks on our code. 

## Business Question
Before we start loading our data on Pandas and starting analysis, let's first understand our business question and our data. The dataset was originally utilized by [Sakar et al](https://link.springer.com/article/10.1007/s00521-018-3523-0) to propose a real-time online shopper behavior analysis system. The goal of the paper was to predict the purchasing intention of the customer and website abandonment likelihood. In this series, we will focus on the former and analyze and predict which behaviors of a customer will result to a higher likelihood of making a purchase. 

## Dataloading and Understanding the Data
Let's load our data on pandas while we understand it's background further using related literature. There are 10 numerical and 8 categorical attributes. The "Revenue" attribute, which indicates if a visit resulted to a customer transaction, will be our indepednent variable. 

```python
df = pd.read_csv('./dataset/online_shoppers_intention.csv')
```

The following tables are Table 1 and Table 2 of [Sakar et al](https://link.springer.com/article/10.1007/s00521-018-3523-0).

 **Table 1:** Numerical Attributes 

---

| Attribute      | Description |
| :---        |    :---:   |
| Adminsitrative      | No. of pages visited by the visitor about account management       |
| Administrative Duration   | Amount of time in sec spent on administrative pages        |
| Informational | No. of pages visited by vistor about web site, contect, and address info |
| Informational Duration | Amount of time in sec spent on informational pages|
| Product Related | No. of pages visited by vistor about product |
| Product Related Duration | Amount of time in sec spent on product pages |
| Bounce Rate | Average bounce rate value of pages visited by visitor |
| Exit Rate | Average exit rate value of the pages visited by visitor |
| Page Value | Average page value o the pages visited by visitor | 
| Special Data | Closeness of site visting time to a spefial day |

--- 

 **Table 2:** Categorical Attributes 

---

| Attribute      | Description | No. of Categories |
| :---        |    :---:   | :---: | 
| OperatingSystems | Operating System of visitor | 8 |
| Browser | Browser | 13 |
| Region | Georgraphic loctation of the visitor | 9 |
| Traffic Type | Traffic source by which the visitor arrived | 20 |
| Visitor Type | "New Visitor", "Returning Visitor", "Other" | 3 |
| Weekend | boolean value if visit was made on a weekend | 2 |
| Month | Month | 12 |
| Revenue | Indicates if visit ended with a transaction | 2 |

---

## The Data

Now let's look at the shape of our data and it's attributes.

```python
import pandas

# shape
print(df.shape)
# show data types
print(df.dtypes)
```

```
(12330, 18)

[5 rows x 18 columns]
Administrative               int64
Administrative_Duration    float64
Informational                int64
Informational_Duration     float64
ProductRelated               int64
ProductRelated_Duration    float64
BounceRates                float64
ExitRates                  float64
PageValues                 float64
SpecialDay                 float64
Month                       object
OperatingSystems             int64
Browser                      int64
Region                       int64
TrafficType                  int64
VisitorType                 object
Weekend                       bool
Revenue                       bool
```

We can see that some of our categorical variables are numeric. This could be useful since we can look at the descriptive statistics of the data without encoding. The describe function accepts both object and numeric data types but having both as input makes the output unreadable so we're going to separate the two.

```python
# descriptive stats
print(df.describe().T)
print(df.describe(include=['object','bool']).T)
```

```python
                           count         mean          std  min         25%         50%          75%           max
Administrative           12330.0     2.315166     3.321784  0.0    0.000000    1.000000     4.000000     27.000000
Administrative_Duration  12330.0    80.818611   176.779107  0.0    0.000000    7.500000    93.256250   3398.750000
Informational            12330.0     0.503569     1.270156  0.0    0.000000    0.000000     0.000000     24.000000
Informational_Duration   12330.0    34.472398   140.749294  0.0    0.000000    0.000000     0.000000   2549.375000
ProductRelated           12330.0    31.731468    44.475503  0.0    7.000000   18.000000    38.000000    705.000000
ProductRelated_Duration  12330.0  1194.746220  1913.669288  0.0  184.137500  598.936905  1464.157214  63973.522230
BounceRates              12330.0     0.022191     0.048488  0.0    0.000000    0.003112     0.016813      0.200000
ExitRates                12330.0     0.043073     0.048597  0.0    0.014286    0.025156     0.050000      0.200000
PageValues               12330.0     5.889258    18.568437  0.0    0.000000    0.000000     0.000000    361.763742
SpecialDay               12330.0     0.061427     0.198917  0.0    0.000000    0.000000     0.000000      1.000000
OperatingSystems         12330.0     2.124006     0.911325  1.0    2.000000    2.000000     3.000000      8.000000
Browser                  12330.0     2.357097     1.717277  1.0    2.000000    2.000000     2.000000     13.000000
Region                   12330.0     3.147364     2.401591  1.0    1.000000    3.000000     4.000000      9.000000
TrafficType              12330.0     4.069586     4.025169  1.0    2.000000    2.000000     4.000000     20.000000
```

```python
             count unique                top   freq
Month        12330     10                May   3364
VisitorType  12330      3  Returning_Visitor  10551
Weekend      12330      2              False   9462
Revenue      12330      2              False  10422
```

We can see that our data is highly skewed especially duration times. For example, Administrative_Duration has a mean of 80.8 seconds with a median (50% percentile) at 7.5 seconds. We would also have to explore the background on how this data was captured since it is possible that it is counting sessions where the vistor has a product page tab open (~17 hours is the max!). There is also a difference in the scale of each variable such as the bounce and exit rates versus duration times. Our outcome of interest "Revenue" also has a class imbalance with almost 80% of the data being of the negative class. We can also check for skewness using the skew function. First let's separate our predictors to continuous and categorical variables in two separate lists. 

```python
# spit our variables according to type
categorical_var = ['SpecialDay','Month','OperatingSystems',
'Browser','Region','TrafficType','VisitorType','Revenue','Weekend']

continuous_var = df.loc[:,~df.columns.isin(categorical_var)].columns

print(df[continuous_var].skew())
```
```python
Administrative             1.960357
Administrative_Duration    5.615719
Informational              4.036464
Informational_Duration     7.579185
ProductRelated             4.341516
ProductRelated_Duration    7.263228
BounceRates                2.947855
ExitRates                  2.148789
PageValues                 6.382964
```

We can see that most if not all of our continuous predictors are skewed. Let's visualize the data further to see the distributions.


## Visualization

For this project, we will be using plotly to visualize our data. Let's go ahead and start plotting some of our continuous variables with "Revenue" as our categorical response or independent variable. All of the plots will be available in the repo. The following is a function that we can reuse to plot different continuous variables with a categorical response.

```python
def plot_cat_resp_cont_predictors(df, predictor, response, f_name, bin_size=1):
    """
    Function plots histogram categorical response with continuous predictor
    """
    # Separate predictors based on response category
    x_false = df[df[response]==False].loc[:,predictor]
    x_true = df[df[response]==True].loc[:,predictor]
    histogram_data = [x_false, x_true]
    labels = ["False","True"]
    fig = ff.create_distplot(histogram_data, labels, bin_size=bin_size)

    # Overlay both histograms
    fig.update_layout(barmode='overlay',
    title="Revenue by " + predictor,
    xaxis_title=predictor,
    yaxis_title="Distribution",
    )
    # Reduce opacity to see both histograms
    fig.update_traces(opacity=0.75)

    fig.write_html(
    file="./output/" + f_name + ".html",
    include_plotlyjs="cdn",
    )

# plot! 
plot_cat_resp_cont_predictors(df, continuous_var[3], "Revenue", continuous_var[3], 30)

```


Let's view the highly skewed "Informational_Duration".

<iframe src="/img/posts/ocsi_part1/Informational_Duration.html" height=600px width="100%"></iframe>

As we can see, it's difficult to visualize the distribution with the skewed data. Let's try applying log transform to "Informational_Duration" to see if it will help visualize our data.

```Python
# log transform the data
df["info_duration_log"] = np.log(df[continuous_var[3]] + 1)
   
plot_cat_resp_cont_predictors(df, "info_duration_log", "Revenue", "info_duration_log", 0.25)

```

<iframe src="/img/posts/ocsi_part1/info_duration_log.html" height=600px width="100%"></iframe>

It's a slight improvement. Well maybe. Maybe not. We will probably have to further explore data transformations in part two, such as Box-Cox transforms. Let's try visualizing some of our categorical data.

```Python
months = df.Month.value_counts().index
fig = go.Figure(data=[
    go.Bar(name='False', x=months, y=df[df["Revenue"] == False].Month.value_counts(normalize=True).to_list()),
    go.Bar(name='True', x=months, y=df[df["Revenue"] == True].Month.value_counts(normalize=True).to_list())
])

# Change the bar mode
fig.update_layout(barmode='stack',
    title="Revenue by Month",
    xaxis_title="Month",
    yaxis_title="Distribution")

```

<iframe src="/img/posts/ocsi_part1/Revenue_by_month.html" height=400px width="100%"></iframe>

We can see that May, Nov, Mar, and Dec are months with significantly higher rates of customer revenue. We will explore more visualization techniques in the next part since it will help us with feature engineering. If you want to check out the full code and the plots, feel free to check out the github [repo]((https://github.com/shadfdz/crispy-octo-spoon)). 

Thanks for the read! I would appreciate comments and feedback on my work. You may do that on the discussion tab on github. Thanks!


##### Acknowledgements
Sakar, C.O., Polat, S.O., Katircioglu, M. et al. Neural Comput & Applic (2018).

